---
layout: post
title: Day17
date: 2023-12-11 12:06 +0800
category: [读研日记]
tags: []
img_path: "/assets/img/posts/"
---

不知道跑了个什么模型，模型名是yolov8-cb，只能从模型结构判断可能是yolov8-cbam

是拿的hic里的cbambottleneck改的，记录一下结果

|Model            |Parameters|GFLOPs|Train Epochs  |Best Epochs   |mAP@50:95| mAP50 |
|:---:            |:---:     |:---: |:---:         |:---:         |:---:    |:---:  |
|yolov8m-cbam     |49431668  |193.8 |168           |118           |0.24842  |0.41506|
|yolov8m          |25902640  |79.3  |174           |124           |0.25743  |0.42222|
|yolov8m-p2       |25544952  |100.6 |177           |127           |0.29308  |0.47413|
|yolov8m-p234     |19093168  |96.4  |162           |112           |0.29442  |0.47566|
|yolov8m-cb       |29306836  |82.1  |169           |119           |0.25789  |0.42233|
|yolov8m-cbam-p234|22497364  |99.2  |170           |170           |0.29072  |0.47285|

哪怕是用了别人的cbam，对于涨点也毫无帮助，网上找了一些资料，推断应该是yolo8m已经足够拟合训练数据，所以cbam毫无作用甚至有可能负优化，用 yolov8n会不会有效果

很奇怪的一点是ultralytics提供的cbam对参数量的提升也太大了，需要再查查

接下来就是backbone的替换，需要找更多的代码来做参考

目前唯一的进展就是检测头对精度有较大提升

整理现有的模型和数据之后选出最优的保留，再做进一步的实验

经过ultralytics和hic实现的cbam对比实验可以发现，两者几乎差不多，之前的参数量暴涨的原因也发现了，是cbam的参数设置的原因看来只需要留下官方实现即可

接下来对cbam的实验集中在放置的位置和参数设置对精度的影响即可

对所有模型重新训练一遍，保留最终的数据，这次用s而不是m
