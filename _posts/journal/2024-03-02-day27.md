---
layout: post
title: Day27
date: 2024-03-02 14:52 +0800
category: [读研日记]
tags: []
img_path: "/assets/img/posts/240302"
---

看了一篇YOLO-TLA

主要工作是:

1. 全局注意力模块(GAM)
2. C3CrossCovn替换Backbone中的C3
3. Neck中添加小目标检测层
4. 添加了一个20x20的检测头并连接到neck中的小目标检测层

这是模型的网络结构

![model overview](image.png)

相对于yolov5,他的改进点主要在于C3CrossConv模块的设计和neck的网络结构修改

依我的经验，注意力机制就是凑数的（

至于C3CrossConv（论文里面把Conv打成Covn不知道是不是故意的）

![C3CrossConv](image-1.png)

上图是C3CrossConv模块

![C3](image-2.png)

上图是C3模块

可以看到就是把C3里的BottleNeck换成了CrossConv

以下是yolov5中C3的BotleNeck

![bottleneck](image-3.png)

可以看到所谓的CrossConv模块就是改了一下Bottleneck的维度

对比yolov5结构不难看出

![todlayer](image-4.png)

这些就是作者添加的小目标检测层

